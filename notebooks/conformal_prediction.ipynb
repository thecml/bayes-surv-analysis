{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\au475271\\Miniconda3\\envs\\py38-fortuna\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "matplotlib_style = 'fivethirtyeight'\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sksurv.linear_model.coxph import BreslowEstimator\n",
    "matplotlib_style = 'fivethirtyeight'\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utility.training import get_data_loader, scale_data_valid, make_time_event_split\n",
    "from tools.model_builder import make_mcd_model\n",
    "from utility.config import load_config\n",
    "from utility.loss import CoxPHLoss\n",
    "import paths as pt\n",
    "from utility.survival import get_breslow_survival_times, compute_survival_times\n",
    "from utility.risk import InputFunction\n",
    "from tools.model_trainer import Trainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "N_EPOCHS = 1\n",
    "MLP_RUNS = 1\n",
    "VI_RUNS = 100\n",
    "MCD_RUNS = 100\n",
    "DATASET_NAME = \"SEER\"\n",
    "MODEL_VERSION = \"FULL\"\n",
    "\n",
    "# Load config\n",
    "config = load_config(pt.MLP_CONFIGS_DIR, f\"{DATASET_NAME}.yaml\")\n",
    "optimizer = tf.keras.optimizers.deserialize(config['optimizer'])\n",
    "loss_fn = CoxPHLoss()\n",
    "activation_fn = config['activiation_fn']\n",
    "layers = config['network_layers']\n",
    "dropout_rate = config['dropout_rate']\n",
    "l2_reg = config['l2_reg']\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "# Load data\n",
    "dl = get_data_loader(DATASET_NAME).load_data()\n",
    "X, y = dl.get_data()\n",
    "num_features, cat_features = dl.get_features()\n",
    "\n",
    "# Split data in train, valid and test set\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "# Scale data\n",
    "X_train, X_valid, X_test = scale_data_valid(X_train, X_valid, X_test, cat_features, num_features)\n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Make time/event split\n",
    "t_train, e_train = make_time_event_split(y_train)\n",
    "t_valid, e_valid = make_time_event_split(y_valid)\n",
    "t_test, e_test = make_time_event_split(y_test)\n",
    "\n",
    "# Make event times\n",
    "lower, upper = np.percentile(t_test[t_test.dtype.names], [10, 90])\n",
    "event_times = np.arange(lower, upper+1)\n",
    "\n",
    "# Create model instance\n",
    "mcd_model = make_mcd_model(input_shape=X_train.shape[1:], output_dim=2,\n",
    "                           layers=layers, activation_fn=activation_fn,\n",
    "                           dropout_rate=dropout_rate, regularization_pen=l2_reg)\n",
    "\n",
    "# Make data loaders\n",
    "train_ds = InputFunction(X_train, t_train, e_train, batch_size=batch_size, drop_last=True, shuffle=True)()\n",
    "valid_ds = InputFunction(X_valid, t_valid, e_valid, batch_size=batch_size)() \n",
    "test_ds = InputFunction(X_test, t_test, e_test, batch_size=batch_size)()\n",
    "\n",
    "# Make model\n",
    "mcd_model = make_mcd_model(input_shape=X_train.shape[1:], output_dim=2,\n",
    "                           layers=layers, activation_fn=activation_fn,\n",
    "                           dropout_rate=dropout_rate, regularization_pen=l2_reg)\n",
    "\n",
    "# Make trainer\n",
    "trainer = Trainer(model=mcd_model, model_name=\"MCD\",\n",
    "                  train_dataset=train_ds, valid_dataset=None,\n",
    "                  test_dataset=test_ds, optimizer=optimizer,\n",
    "                  loss_function=loss_fn, num_epochs=N_EPOCHS,\n",
    "                  event_times=event_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed MCD epoch 1/1\n",
      "Model test variance: 0.8113531060665515\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train_and_evaluate()\n",
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only uncensored times\n",
    "valid_idx = list(np.where(y_valid['event'] == True)[0])\n",
    "X_valid = X_valid[valid_idx]\n",
    "test_idx = list(np.where(y_test['event'] == True)[0])\n",
    "X_test = X_test[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "valid_model_cpd = np.zeros((n_samples, len(X_valid)))\n",
    "for i in range(0, n_samples):\n",
    "    pred = np.reshape(model.predict(X_valid, verbose=0), len(X_valid))\n",
    "    valid_model_cpd[i,:] = compute_survival_times(pred, t_train, e_train)\n",
    "\n",
    "valid_means = np.mean(valid_model_cpd, axis=0)\n",
    "valid_vars = np.var(valid_model_cpd, axis=0)\n",
    "valid_stds = np.std(valid_model_cpd, axis=0)\n",
    "\n",
    "test_model_cpd = np.zeros((n_samples, len(X_test)))\n",
    "for i in range(0, n_samples):\n",
    "    pred = np.reshape(model.predict(X_test, verbose=0), len(X_test))\n",
    "    test_model_cpd[i,:] = compute_survival_times(pred, t_train, e_train)\n",
    "test_means = np.mean(test_model_cpd, axis=0)\n",
    "test_vars = np.var(test_model_cpd, axis=0)\n",
    "test_stds = np.std(test_model_cpd, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_outputs = np.concatenate((valid_means[:,np.newaxis], np.log(valid_vars)[:,np.newaxis]), axis=-1)\n",
    "test_outputs = np.concatenate((test_means[:,np.newaxis], np.log(test_vars)[:,np.newaxis]), axis=-1)\n",
    "calib_targets = y_valid[y_valid['event'] == True]['time'][:,np.newaxis]\n",
    "test_targets = y_test[y_test['event'] == True]['time'][:,np.newaxis]\n",
    "valid_means = valid_means[:,np.newaxis]\n",
    "valid_stds = valid_stds[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Epoch: 100 | loss: 34.17826: 100%|██████████| 100/100 [00:00<00:00, 269.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from fortuna.output_calib_model import OutputCalibRegressor, Config, Monitor\n",
    "\n",
    "calib_model = OutputCalibRegressor()\n",
    "calib_status = calib_model.calibrate(\n",
    "    calib_outputs=calib_outputs,\n",
    "    calib_targets=calib_targets,\n",
    "    config=Config(monitor=Monitor(early_stopping_patience=2)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fortuna.output_calib_model.regression.OutputCalibRegressor at 0x1b3e63f8670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_probs = calib_model.predictive.log_prob(\n",
    "    outputs=test_outputs, targets=test_targets\n",
    ")\n",
    "test_means = calib_model.predictive.mean(outputs=test_outputs)\n",
    "test_variances = calib_model.predictive.variance(outputs=test_outputs)\n",
    "test_stds = calib_model.predictive.std(outputs=test_outputs, variances=test_variances)\n",
    "test_cred_intervals = calib_model.predictive.credible_interval(outputs=test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 84.87664031982422\n"
     ]
    }
   ],
   "source": [
    "from fortuna.metric.regression import root_mean_squared_error\n",
    "rmse = root_mean_squared_error(preds=test_means, targets=test_targets)\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated PICP for 95% conformal intervals of test inputs: 0.7977527976036072\n"
     ]
    }
   ],
   "source": [
    "from fortuna.metric.regression import prediction_interval_coverage_probability\n",
    "\n",
    "conformal_picp = prediction_interval_coverage_probability(\n",
    "    lower_bounds=test_cred_intervals[:, 0],\n",
    "    upper_bounds=test_cred_intervals[:, 1],\n",
    "    targets=test_targets,\n",
    ")\n",
    "print(f\"Calibrated PICP for 95% conformal intervals of test inputs: {conformal_picp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICP for 95% conformal intervals of test inputs: 0.9775280952453613\n"
     ]
    }
   ],
   "source": [
    "from fortuna.conformal import OneDimensionalUncertaintyConformalRegressor\n",
    "test_cred_intervals = (\n",
    "    OneDimensionalUncertaintyConformalRegressor().conformal_interval(\n",
    "        val_preds=valid_means,\n",
    "        val_uncertainties=valid_stds,\n",
    "        test_preds=test_means,\n",
    "        test_uncertainties=test_stds,\n",
    "        val_targets=calib_targets,\n",
    "        error=0.05,\n",
    "    ) \n",
    ")\n",
    "conformal_picp = prediction_interval_coverage_probability(\n",
    "    lower_bounds=test_cred_intervals[:, 0],\n",
    "    upper_bounds=test_cred_intervals[:, 1],\n",
    "    targets=test_targets,\n",
    ")\n",
    "rmse = root_mean_squared_error(preds=test_means, targets=test_targets)\n",
    "print(f\"PICP for 95% conformal intervals of test inputs: {conformal_picp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Brier score as loss function for calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-bayes-surv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
