{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsess = tf.compat.v1.Session()\\n\\ndef evaluate(tensors):\\n    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\\n    Args:\\n    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\\n      `namedtuple` or combinations thereof.\\n\\n    Returns:\\n      ndarrays: Object with same structure as `tensors` except with `Tensor` or\\n        `EagerTensor`s replaced by Numpy `ndarray`s.\\n    \"\"\"\\n    if tf.executing_eagerly():\\n        return tf.contrib.framework.nest.pack_sequence_as(\\n            tensors,\\n            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\\n             for t in tf.contrib.framework.nest.flatten(tensors)])\\n    return sess.run(tensors)\\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data_loader import load_veterans_ds, prepare_veterans_ds\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utility import InputFunction, CindexMetric, CoxPHLoss, _make_riskset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "'''\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "def evaluate(tensors):\n",
    "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
    "    Args:\n",
    "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
    "      `namedtuple` or combinations thereof.\n",
    "\n",
    "    Returns:\n",
    "      ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
    "        `EagerTensor`s replaced by Numpy `ndarray`s.\n",
    "    \"\"\"\n",
    "    if tf.executing_eagerly():\n",
    "        return tf.contrib.framework.nest.pack_sequence_as(\n",
    "            tensors,\n",
    "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
    "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
    "    return sess.run(tensors)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "iteritems is deprecated and will be removed in a future version. Use .items instead.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = load_veterans_ds()\n",
    "t_train, t_valid, t_test, e_train, e_valid, e_test  = prepare_veterans_ds(y_train, y_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.047399>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute risk set for 5 samples\n",
    "n_samples = 5\n",
    "train_event_set = tf.expand_dims(e_train[:n_samples].astype(np.int32), axis=1)\n",
    "train_risks_set = tf.convert_to_tensor(_make_riskset(t_train[:n_samples]))\n",
    "pred_ = tf.convert_to_tensor(np.linspace(0.1, 0.9, n_samples).reshape(n_samples,1).astype(np.float32)) # random prediction\n",
    "\n",
    "# Run loss function\n",
    "loss_fn = CoxPHLoss()\n",
    "loss_fn(y_true=[train_event_set, train_risks_set], y_pred=pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_ = X_train[:,0] # for now, just use 1 feature TODO\n",
    "Y_data_ = t_train # dont use event labels for now TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_stdev = tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Y_data_, tf.reduce_mean(Y_data_, axis=0)), axis=0))\n",
    "\n",
    "# Define the log probability of the bayesian regression function\n",
    "def risk_posterior_log_prob(X_data_, Y_data_, alpha, beta):\n",
    "  \"\"\"\n",
    "  Our posterior log probability, as a function of states\n",
    "\n",
    "  Args:\n",
    "    alpha_: scalar, taken from state of the HMC\n",
    "    beta_: scalar, taken from state of the HMC\n",
    "    sigma_: scalar, the standard deviation of , taken from state of the HMC\n",
    "  Returns: \n",
    "    Scalar sum of log probabilities\n",
    "  Closure over: Y_data, X_data\n",
    "  \"\"\"\n",
    "  # TODO: Implement proper risk calculation here\n",
    "  \n",
    "  rv_std = tfd.Uniform(name=\"std\", low=0., high=100.)\n",
    "  rv_beta = tfd.Normal(name=\"beta\", loc=0., scale=100.)\n",
    "  rv_alpha = tfd.Normal(name=\"alpha\", loc=0., scale=100.)\n",
    "\n",
    "  mean = np.float32(alpha + beta * X_data_)\n",
    "  rv_observed = tfd.Normal(name=\"obs\", loc=mean, scale=1e-3) # hardcoded sigma TODO\n",
    "\n",
    "  return (\n",
    "      rv_alpha.log_prob(alpha)\n",
    "      + rv_beta.log_prob(beta)\n",
    "      + tf.reduce_sum(rv_observed.log_prob(Y_data_))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrv_std = tfd.Uniform(name=\"std\", low=0., high=100.)\\nrv_beta = tfd.Normal(name=\"beta\", loc=0., scale=100.)\\nrv_alpha = tfd.Normal(name=\"alpha\", loc=0., scale=100.)\\nalpha = tf.cast(1.,dtype=tf.float32) * tf.ones([], name=\\'init_alpha\\', dtype=tf.float32),\\nbeta = tf.cast(0.01,dtype=tf.float32) * tf.ones([], name=\\'init_beta\\', dtype=tf.float32),\\nsigma = tf.cast(obs_stdev,dtype=tf.float32) * tf.ones([], name=\\'init_sigma\\', dtype=tf.float32)\\nmean = np.float32(alpha + beta * X_data_)\\nrv_observed = tfd.Normal(name=\"obs\", loc=mean, scale=sigma)\\nrv_alpha.log_prob(alpha) + rv_beta.log_prob(beta) + tf.reduce_sum(rv_observed.log_prob(Y_data_)) # causes -inf TODO\\n'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "rv_std = tfd.Uniform(name=\"std\", low=0., high=100.)\n",
    "rv_beta = tfd.Normal(name=\"beta\", loc=0., scale=100.)\n",
    "rv_alpha = tfd.Normal(name=\"alpha\", loc=0., scale=100.)\n",
    "alpha = tf.cast(1.,dtype=tf.float32) * tf.ones([], name='init_alpha', dtype=tf.float32),\n",
    "beta = tf.cast(0.01,dtype=tf.float32) * tf.ones([], name='init_beta', dtype=tf.float32),\n",
    "sigma = tf.cast(obs_stdev,dtype=tf.float32) * tf.ones([], name='init_sigma', dtype=tf.float32)\n",
    "mean = np.float32(alpha + beta * X_data_)\n",
    "rv_observed = tfd.Normal(name=\"obs\", loc=mean, scale=sigma)\n",
    "rv_alpha.log_prob(alpha) + rv_beta.log_prob(beta) + tf.reduce_sum(rv_observed.log_prob(Y_data_)) # causes -inf TODO\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps = 30000\n",
    "burnin = 5000\n",
    "\n",
    "# Set the chain's start state.\n",
    "initial_chain_state = [\n",
    "    tf.cast(1.,dtype=tf.float32) * tf.ones([], name='init_alpha', dtype=tf.float32),\n",
    "    tf.cast(0.01,dtype=tf.float32) * tf.ones([], name='init_beta', dtype=tf.float32),\n",
    "]\n",
    "\n",
    "unconstraining_bijectors = [\n",
    "    tfp.bijectors.Identity(), #alpha\n",
    "    tfp.bijectors.Identity(), #beta # Figure out proper bijector for beta TODO\n",
    "]\n",
    "\n",
    "unnormalized_posterior_log_prob = lambda *args: risk_posterior_log_prob(X_data_, Y_data_, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[204], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m kernel \u001b[39m=\u001b[39m tfp\u001b[39m.\u001b[39mmcmc\u001b[39m.\u001b[39mSimpleStepSizeAdaptation(\n\u001b[0;32m     14\u001b[0m     inner_kernel\u001b[39m=\u001b[39mkernel, num_adaptation_steps\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(burnin \u001b[39m*\u001b[39m \u001b[39m0.8\u001b[39m))\n\u001b[0;32m     16\u001b[0m \u001b[39m# Sampling from the chain.\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m [alpha, beta, sigma], kernel_results \u001b[39m=\u001b[39m tfp\u001b[39m.\u001b[39;49mmcmc\u001b[39m.\u001b[39;49msample_chain(\n\u001b[0;32m     18\u001b[0m     num_results \u001b[39m=\u001b[39;49m number_of_steps,\n\u001b[0;32m     19\u001b[0m     num_burnin_steps \u001b[39m=\u001b[39;49m burnin,\n\u001b[0;32m     20\u001b[0m     current_state\u001b[39m=\u001b[39;49minitial_chain_state,\n\u001b[0;32m     21\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m     22\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHMC_sampling\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[39m# Initialize any created variables for preconditions\u001b[39;00m\n\u001b[0;32m     26\u001b[0m init_g \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mglobal_variables_initializer()\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py:359\u001b[0m, in \u001b[0;36msample_chain\u001b[1;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[0;32m    352\u001b[0m   seed, next_state, current_kernel_results \u001b[39m=\u001b[39m loop_util\u001b[39m.\u001b[39msmart_for_loop(\n\u001b[0;32m    353\u001b[0m       loop_num_iter\u001b[39m=\u001b[39mnum_steps,\n\u001b[0;32m    354\u001b[0m       body_fn\u001b[39m=\u001b[39m_seeded_one_step,\n\u001b[0;32m    355\u001b[0m       initial_loop_vars\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(seed_state_and_results),\n\u001b[0;32m    356\u001b[0m       parallel_iterations\u001b[39m=\u001b[39mparallel_iterations)\n\u001b[0;32m    357\u001b[0m   \u001b[39mreturn\u001b[39;00m seed, next_state, current_kernel_results\n\u001b[1;32m--> 359\u001b[0m (_, _, final_kernel_results), (all_states, trace) \u001b[39m=\u001b[39m loop_util\u001b[39m.\u001b[39;49mtrace_scan(\n\u001b[0;32m    360\u001b[0m     loop_fn\u001b[39m=\u001b[39;49m_trace_scan_fn,\n\u001b[0;32m    361\u001b[0m     initial_state\u001b[39m=\u001b[39;49m(seed, current_state, previous_kernel_results),\n\u001b[0;32m    362\u001b[0m     elems\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mone_hot(\n\u001b[0;32m    363\u001b[0m         indices\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m    364\u001b[0m         depth\u001b[39m=\u001b[39;49mnum_results,\n\u001b[0;32m    365\u001b[0m         on_value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m+\u001b[39;49m num_burnin_steps,\n\u001b[0;32m    366\u001b[0m         off_value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m+\u001b[39;49m num_steps_between_results,\n\u001b[0;32m    367\u001b[0m         dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mint32),\n\u001b[0;32m    368\u001b[0m     \u001b[39m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    369\u001b[0m     trace_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m seed_state_and_results: (\n\u001b[0;32m    370\u001b[0m         seed_state_and_results[\u001b[39m1\u001b[39;49m], trace_fn(\u001b[39m*\u001b[39;49mseed_state_and_results[\u001b[39m1\u001b[39;49m:])),\n\u001b[0;32m    371\u001b[0m     \u001b[39m# pylint: enable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    372\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m return_final_kernel_results:\n\u001b[0;32m    375\u001b[0m   \u001b[39mreturn\u001b[39;00m CheckpointableStatesAndTrace(\n\u001b[0;32m    376\u001b[0m       all_states\u001b[39m=\u001b[39mall_states,\n\u001b[0;32m    377\u001b[0m       trace\u001b[39m=\u001b[39mtrace,\n\u001b[0;32m    378\u001b[0m       final_kernel_results\u001b[39m=\u001b[39mfinal_kernel_results)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py:222\u001b[0m, in \u001b[0;36mtrace_scan\u001b[1;34m(loop_fn, initial_state, elems, trace_fn, trace_criterion_fn, static_trace_allocation_size, condition_fn, parallel_iterations, name)\u001b[0m\n\u001b[0;32m    214\u001b[0m   trace_arrays, num_steps_traced \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mcond(\n\u001b[0;32m    215\u001b[0m       trace_criterion_fn(state) \u001b[39mif\u001b[39;00m trace_criterion_fn \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m       \u001b[39mlambda\u001b[39;00m: (trace_one_step(num_steps_traced, trace_arrays, state),  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    217\u001b[0m                num_steps_traced \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m),\n\u001b[0;32m    218\u001b[0m       \u001b[39mlambda\u001b[39;00m: (trace_arrays, num_steps_traced))\n\u001b[0;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, state, num_steps_traced, trace_arrays\n\u001b[1;32m--> 222\u001b[0m _, final_state, _, trace_arrays \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m    223\u001b[0m     cond\u001b[39m=\u001b[39;49mcondition_fn \u001b[39mif\u001b[39;49;00m condition_fn \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49m_: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    224\u001b[0m     body\u001b[39m=\u001b[39;49m_body,\n\u001b[0;32m    225\u001b[0m     loop_vars\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, initial_state, \u001b[39m0\u001b[39;49m, trace_arrays),\n\u001b[0;32m    226\u001b[0m     maximum_iterations\u001b[39m=\u001b[39;49mlength,\n\u001b[0;32m    227\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations)\n\u001b[0;32m    229\u001b[0m \u001b[39m# unflatten\u001b[39;00m\n\u001b[0;32m    230\u001b[0m stacked_trace \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    231\u001b[0m     initial_trace, [ta\u001b[39m.\u001b[39mstack() \u001b[39mfor\u001b[39;00m ta \u001b[39min\u001b[39;00m trace_arrays],\n\u001b[0;32m    232\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[0;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2516\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2340\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2341\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[0;32m   2342\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2357\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2358\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2359\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m \n\u001b[0;32m   2361\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \n\u001b[0;32m   2515\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[0;32m   2517\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m   2518\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m   2519\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[0;32m   2520\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[0;32m   2521\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m   2522\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m   2523\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m   2524\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2525\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[0;32m   2526\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2765\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2762\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2763\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[0;32m   2764\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[1;32m-> 2765\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[0;32m   2766\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[0;32m   2767\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2756\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2753\u001b[0m     loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[0;32m   2754\u001b[0m     cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m   2755\u001b[0m         math_ops\u001b[39m.\u001b[39mlogical_and(i \u001b[39m<\u001b[39m maximum_iterations, orig_cond(\u001b[39m*\u001b[39mlv)))\n\u001b[1;32m-> 2756\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39;49mlv))\n\u001b[0;32m   2757\u001b[0m   try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py:212\u001b[0m, in \u001b[0;36mtrace_scan.<locals>._body\u001b[1;34m(i, state, num_steps_traced, trace_arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_body\u001b[39m(i, state, num_steps_traced, trace_arrays):\n\u001b[0;32m    211\u001b[0m   elem \u001b[39m=\u001b[39m elems_array\u001b[39m.\u001b[39mread(i)\n\u001b[1;32m--> 212\u001b[0m   state \u001b[39m=\u001b[39m loop_fn(state, elem)\n\u001b[0;32m    214\u001b[0m   trace_arrays, num_steps_traced \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mcond(\n\u001b[0;32m    215\u001b[0m       trace_criterion_fn(state) \u001b[39mif\u001b[39;00m trace_criterion_fn \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m       \u001b[39mlambda\u001b[39;00m: (trace_one_step(num_steps_traced, trace_arrays, state),  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    217\u001b[0m                num_steps_traced \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m),\n\u001b[0;32m    218\u001b[0m       \u001b[39mlambda\u001b[39;00m: (trace_arrays, num_steps_traced))\n\u001b[0;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, state, num_steps_traced, trace_arrays\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py:352\u001b[0m, in \u001b[0;36msample_chain.<locals>._trace_scan_fn\u001b[1;34m(seed_state_and_results, num_steps)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_trace_scan_fn\u001b[39m(seed_state_and_results, num_steps):\n\u001b[1;32m--> 352\u001b[0m   seed, next_state, current_kernel_results \u001b[39m=\u001b[39m loop_util\u001b[39m.\u001b[39;49msmart_for_loop(\n\u001b[0;32m    353\u001b[0m       loop_num_iter\u001b[39m=\u001b[39;49mnum_steps,\n\u001b[0;32m    354\u001b[0m       body_fn\u001b[39m=\u001b[39;49m_seeded_one_step,\n\u001b[0;32m    355\u001b[0m       initial_loop_vars\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(seed_state_and_results),\n\u001b[0;32m    356\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations)\n\u001b[0;32m    357\u001b[0m   \u001b[39mreturn\u001b[39;00m seed, next_state, current_kernel_results\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py:97\u001b[0m, in \u001b[0;36msmart_for_loop\u001b[1;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, unroll_threshold, name)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m (loop_num_iter_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[39mor\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m     89\u001b[0m     \u001b[39m# large values for loop_num_iter_ will cause ridiculously slow\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[39m# Cast to int32 to run the comparison against i in host memory,\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[39m# where while/LoopCond needs it.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m   loop_num_iter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(loop_num_iter, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)\n\u001b[1;32m---> 97\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m     98\u001b[0m       cond\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m i, \u001b[39m*\u001b[39;49margs: i \u001b[39m<\u001b[39;49m loop_num_iter,\n\u001b[0;32m     99\u001b[0m       body\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m i, \u001b[39m*\u001b[39;49margs: [i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(body_fn(\u001b[39m*\u001b[39;49margs)),\n\u001b[0;32m    100\u001b[0m       loop_vars\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mint32(\u001b[39m0\u001b[39;49m)] \u001b[39m+\u001b[39;49m initial_loop_vars,\n\u001b[0;32m    101\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations\n\u001b[0;32m    102\u001b[0m   )[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    103\u001b[0m result \u001b[39m=\u001b[39m initial_loop_vars\n\u001b[0;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(loop_num_iter_):\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[0;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2516\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2340\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2341\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[0;32m   2342\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2357\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2358\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2359\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m \n\u001b[0;32m   2361\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \n\u001b[0;32m   2515\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[0;32m   2517\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m   2518\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m   2519\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[0;32m   2520\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[0;32m   2521\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m   2522\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m   2523\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m   2524\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2525\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[0;32m   2526\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2765\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2762\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2763\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[0;32m   2764\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[1;32m-> 2765\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[0;32m   2766\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[0;32m   2767\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py:99\u001b[0m, in \u001b[0;36msmart_for_loop.<locals>.<lambda>\u001b[1;34m(i, *args)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m (loop_num_iter_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[39mor\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m     89\u001b[0m     \u001b[39m# large values for loop_num_iter_ will cause ridiculously slow\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[39m# Cast to int32 to run the comparison against i in host memory,\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[39m# where while/LoopCond needs it.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m   loop_num_iter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(loop_num_iter, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     97\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mwhile_loop(\n\u001b[0;32m     98\u001b[0m       cond\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m i, \u001b[39m*\u001b[39margs: i \u001b[39m<\u001b[39m loop_num_iter,\n\u001b[1;32m---> 99\u001b[0m       body\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m i, \u001b[39m*\u001b[39margs: [i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(body_fn(\u001b[39m*\u001b[39;49margs)),\n\u001b[0;32m    100\u001b[0m       loop_vars\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mint32(\u001b[39m0\u001b[39m)] \u001b[39m+\u001b[39m initial_loop_vars,\n\u001b[0;32m    101\u001b[0m       parallel_iterations\u001b[39m=\u001b[39mparallel_iterations\n\u001b[0;32m    102\u001b[0m   )[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    103\u001b[0m result \u001b[39m=\u001b[39m initial_loop_vars\n\u001b[0;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(loop_num_iter_):\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py:349\u001b[0m, in \u001b[0;36msample_chain.<locals>._seeded_one_step\u001b[1;34m(seed, *state_and_results)\u001b[0m\n\u001b[0;32m    345\u001b[0m step_seed, passalong_seed \u001b[39m=\u001b[39m (\n\u001b[0;32m    346\u001b[0m     samplers\u001b[39m.\u001b[39msplit_seed(seed) \u001b[39mif\u001b[39;00m is_seeded \u001b[39melse\u001b[39;00m (\u001b[39mNone\u001b[39;00m, seed))\n\u001b[0;32m    347\u001b[0m one_step_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(seed\u001b[39m=\u001b[39mstep_seed) \u001b[39mif\u001b[39;00m is_seeded \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m [passalong_seed] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m--> 349\u001b[0m     kernel\u001b[39m.\u001b[39;49mone_step(\u001b[39m*\u001b[39;49mstate_and_results, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mone_step_kwargs))\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\simple_step_size_adaptation.py:354\u001b[0m, in \u001b[0;36mSimpleStepSizeAdaptation.one_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m# Step the inner kernel.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m inner_kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mdict\u001b[39m(seed\u001b[39m=\u001b[39mseed)\n\u001b[1;32m--> 354\u001b[0m new_state, new_inner_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner_kernel\u001b[39m.\u001b[39;49mone_step(\n\u001b[0;32m    355\u001b[0m     current_state, inner_results, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minner_kwargs)\n\u001b[0;32m    357\u001b[0m \u001b[39m# Get the new step size.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m log_accept_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_accept_prob_getter_fn(new_inner_results)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\transformed_kernel.py:400\u001b[0m, in \u001b[0;36mTransformedTransitionKernel.one_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    398\u001b[0m inner_kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mdict\u001b[39m(seed\u001b[39m=\u001b[39mseed)\n\u001b[0;32m    399\u001b[0m transformed_prev_state \u001b[39m=\u001b[39m previous_kernel_results\u001b[39m.\u001b[39mtransformed_state\n\u001b[1;32m--> 400\u001b[0m transformed_next_state, kernel_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inner_kernel\u001b[39m.\u001b[39;49mone_step(\n\u001b[0;32m    401\u001b[0m     transformed_prev_state,\n\u001b[0;32m    402\u001b[0m     previous_kernel_results\u001b[39m.\u001b[39;49minner_results,\n\u001b[0;32m    403\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minner_kwargs)\n\u001b[0;32m    404\u001b[0m transformed_next_state_parts \u001b[39m=\u001b[39m (\n\u001b[0;32m    405\u001b[0m     transformed_next_state\n\u001b[0;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m mcmc_util\u001b[39m.\u001b[39mis_list_like(transformed_next_state) \u001b[39melse\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     [transformed_next_state])\n\u001b[0;32m    408\u001b[0m next_state_parts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_unconstrained_to_target_support(\n\u001b[0;32m    409\u001b[0m     transformed_next_state_parts)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\hmc.py:549\u001b[0m, in \u001b[0;36mHamiltonianMonteCarlo.one_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    541\u001b[0m previous_step_size_assign \u001b[39m=\u001b[39m (\n\u001b[0;32m    542\u001b[0m     [] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size_update_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# pylint: disable=g-long-ternary\u001b[39;00m\n\u001b[0;32m    543\u001b[0m     \u001b[39melse\u001b[39;00m (previous_kernel_results\u001b[39m.\u001b[39mextra\u001b[39m.\u001b[39mstep_size_assign  \u001b[39m# pylint: disable=g-long-ternary\u001b[39;00m\n\u001b[0;32m    544\u001b[0m           \u001b[39mif\u001b[39;00m mcmc_util\u001b[39m.\u001b[39mis_list_like(\n\u001b[0;32m    545\u001b[0m               previous_kernel_results\u001b[39m.\u001b[39mextra\u001b[39m.\u001b[39mstep_size_assign)\n\u001b[0;32m    546\u001b[0m           \u001b[39melse\u001b[39;00m [previous_kernel_results\u001b[39m.\u001b[39mextra\u001b[39m.\u001b[39mstep_size_assign]))\n\u001b[0;32m    548\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(previous_step_size_assign):\n\u001b[1;32m--> 549\u001b[0m   next_state, kernel_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impl\u001b[39m.\u001b[39;49mone_step(\n\u001b[0;32m    550\u001b[0m       current_state, previous_kernel_results, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    551\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size_update_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     step_size_assign \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size_update_fn(  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size, kernel_results)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\metropolis_hastings.py:191\u001b[0m, in \u001b[0;36mMetropolisHastings.one_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(mcmc_util\u001b[39m.\u001b[39mmake_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m'\u001b[39m\u001b[39mmh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mone_step\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m    186\u001b[0m   \u001b[39m# Take one inner step.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m   inner_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(seed\u001b[39m=\u001b[39mproposal_seed) \u001b[39mif\u001b[39;00m is_seeded \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m    188\u001b[0m   [\n\u001b[0;32m    189\u001b[0m       proposed_state,\n\u001b[0;32m    190\u001b[0m       proposed_results,\n\u001b[1;32m--> 191\u001b[0m   ] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner_kernel\u001b[39m.\u001b[39;49mone_step(\n\u001b[0;32m    192\u001b[0m       current_state,\n\u001b[0;32m    193\u001b[0m       previous_kernel_results\u001b[39m.\u001b[39;49maccepted_results,\n\u001b[0;32m    194\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minner_kwargs)\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m mcmc_util\u001b[39m.\u001b[39mis_list_like(current_state):\n\u001b[0;32m    196\u001b[0m     proposed_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(current_state, proposed_state)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\hmc.py:739\u001b[0m, in \u001b[0;36mUncalibratedHamiltonianMonteCarlo.one_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    725\u001b[0m   current_momentum_parts\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    726\u001b[0m       samplers\u001b[39m.\u001b[39mnormal(\n\u001b[0;32m    727\u001b[0m           shape\u001b[39m=\u001b[39mps\u001b[39m.\u001b[39mshape(x),\n\u001b[0;32m    728\u001b[0m           dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_momentum_dtype \u001b[39mor\u001b[39;00m dtype_util\u001b[39m.\u001b[39mbase_dtype(x\u001b[39m.\u001b[39mdtype),\n\u001b[0;32m    729\u001b[0m           seed\u001b[39m=\u001b[39mpart_seed))\n\u001b[0;32m    731\u001b[0m integrator \u001b[39m=\u001b[39m leapfrog_impl\u001b[39m.\u001b[39mSimpleLeapfrogIntegrator(\n\u001b[0;32m    732\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_log_prob_fn, step_sizes, num_leapfrog_steps)\n\u001b[0;32m    734\u001b[0m [\n\u001b[0;32m    735\u001b[0m     next_momentum_parts,\n\u001b[0;32m    736\u001b[0m     next_state_parts,\n\u001b[0;32m    737\u001b[0m     next_target_log_prob,\n\u001b[0;32m    738\u001b[0m     next_target_log_prob_grad_parts,\n\u001b[1;32m--> 739\u001b[0m ] \u001b[39m=\u001b[39m integrator(current_momentum_parts,\n\u001b[0;32m    740\u001b[0m                current_state_parts,\n\u001b[0;32m    741\u001b[0m                current_target_log_prob,\n\u001b[0;32m    742\u001b[0m                current_target_log_prob_grad_parts)\n\u001b[0;32m    743\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_gradients_are_stopped:\n\u001b[0;32m    744\u001b[0m   next_state_parts \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mstop_gradient(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m next_state_parts]\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py:291\u001b[0m, in \u001b[0;36mSimpleLeapfrogIntegrator.__call__\u001b[1;34m(self, momentum_parts, state_parts, target, target_grad_parts, kinetic_energy_fn, name)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m# See Algorithm 1 of \"Faster Hamiltonian Monte Carlo by Learning Leapfrog\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m# Scale\", https://arxiv.org/abs/1810.04449.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m half_next_momentum_parts \u001b[39m=\u001b[39m [\n\u001b[0;32m    281\u001b[0m     v \u001b[39m+\u001b[39m _multiply(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m eps, g, dtype\u001b[39m=\u001b[39mv\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m v, eps, g\n\u001b[0;32m    283\u001b[0m     \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(momentum_parts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_sizes, target_grad_parts)]\n\u001b[0;32m    285\u001b[0m [\n\u001b[0;32m    286\u001b[0m     _,\n\u001b[0;32m    287\u001b[0m     next_half_next_momentum_parts,\n\u001b[0;32m    288\u001b[0m     next_state_parts,\n\u001b[0;32m    289\u001b[0m     next_target,\n\u001b[0;32m    290\u001b[0m     next_target_grad_parts,\n\u001b[1;32m--> 291\u001b[0m ] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m    292\u001b[0m     cond\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m i, \u001b[39m*\u001b[39;49m_: i \u001b[39m<\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_steps,\n\u001b[0;32m    293\u001b[0m     body\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m i, \u001b[39m*\u001b[39;49margs: [i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(_one_step(  \u001b[39m# pylint: disable=no-value-for-parameter,g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    294\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_sizes, get_velocity_parts, \u001b[39m*\u001b[39;49margs)),\n\u001b[0;32m    295\u001b[0m     loop_vars\u001b[39m=\u001b[39;49m[\n\u001b[0;32m    296\u001b[0m         tf\u001b[39m.\u001b[39;49mzeros_like(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_steps, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39miter\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m    297\u001b[0m         half_next_momentum_parts,\n\u001b[0;32m    298\u001b[0m         state_parts,\n\u001b[0;32m    299\u001b[0m         target,\n\u001b[0;32m    300\u001b[0m         target_grad_parts,\n\u001b[0;32m    301\u001b[0m     ])\n\u001b[0;32m    303\u001b[0m next_momentum_parts \u001b[39m=\u001b[39m [\n\u001b[0;32m    304\u001b[0m     v \u001b[39m-\u001b[39m _multiply(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m eps, g, dtype\u001b[39m=\u001b[39mv\u001b[39m.\u001b[39mdtype)  \u001b[39m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     \u001b[39mfor\u001b[39;00m v, eps, g\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m            next_target_grad_parts)\n\u001b[0;32m    309\u001b[0m ]\n\u001b[0;32m    311\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    312\u001b[0m     next_momentum_parts,\n\u001b[0;32m    313\u001b[0m     next_state_parts,\n\u001b[0;32m    314\u001b[0m     next_target,\n\u001b[0;32m    315\u001b[0m     next_target_grad_parts,\n\u001b[0;32m    316\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[0;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2516\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2340\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2341\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[0;32m   2342\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2357\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2358\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2359\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m \n\u001b[0;32m   2361\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \n\u001b[0;32m   2515\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[0;32m   2517\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m   2518\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m   2519\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[0;32m   2520\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[0;32m   2521\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m   2522\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m   2523\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m   2524\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2525\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[0;32m   2526\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2765\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2762\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2763\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[0;32m   2764\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[1;32m-> 2765\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[0;32m   2766\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[0;32m   2767\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py:293\u001b[0m, in \u001b[0;36mSimpleLeapfrogIntegrator.__call__.<locals>.<lambda>\u001b[1;34m(i, *args)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m# See Algorithm 1 of \"Faster Hamiltonian Monte Carlo by Learning Leapfrog\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m# Scale\", https://arxiv.org/abs/1810.04449.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m half_next_momentum_parts \u001b[39m=\u001b[39m [\n\u001b[0;32m    281\u001b[0m     v \u001b[39m+\u001b[39m _multiply(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m eps, g, dtype\u001b[39m=\u001b[39mv\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m v, eps, g\n\u001b[0;32m    283\u001b[0m     \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(momentum_parts, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_sizes, target_grad_parts)]\n\u001b[0;32m    285\u001b[0m [\n\u001b[0;32m    286\u001b[0m     _,\n\u001b[0;32m    287\u001b[0m     next_half_next_momentum_parts,\n\u001b[0;32m    288\u001b[0m     next_state_parts,\n\u001b[0;32m    289\u001b[0m     next_target,\n\u001b[0;32m    290\u001b[0m     next_target_grad_parts,\n\u001b[0;32m    291\u001b[0m ] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mwhile_loop(\n\u001b[0;32m    292\u001b[0m     cond\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m i, \u001b[39m*\u001b[39m_: i \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_steps,\n\u001b[1;32m--> 293\u001b[0m     body\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m i, \u001b[39m*\u001b[39margs: [i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(_one_step(  \u001b[39m# pylint: disable=no-value-for-parameter,g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    294\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_fn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_sizes, get_velocity_parts, \u001b[39m*\u001b[39;49margs)),\n\u001b[0;32m    295\u001b[0m     loop_vars\u001b[39m=\u001b[39m[\n\u001b[0;32m    296\u001b[0m         tf\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_steps, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39miter\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    297\u001b[0m         half_next_momentum_parts,\n\u001b[0;32m    298\u001b[0m         state_parts,\n\u001b[0;32m    299\u001b[0m         target,\n\u001b[0;32m    300\u001b[0m         target_grad_parts,\n\u001b[0;32m    301\u001b[0m     ])\n\u001b[0;32m    303\u001b[0m next_momentum_parts \u001b[39m=\u001b[39m [\n\u001b[0;32m    304\u001b[0m     v \u001b[39m-\u001b[39m _multiply(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m eps, g, dtype\u001b[39m=\u001b[39mv\u001b[39m.\u001b[39mdtype)  \u001b[39m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     \u001b[39mfor\u001b[39;00m v, eps, g\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m            next_target_grad_parts)\n\u001b[0;32m    309\u001b[0m ]\n\u001b[0;32m    311\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    312\u001b[0m     next_momentum_parts,\n\u001b[0;32m    313\u001b[0m     next_state_parts,\n\u001b[0;32m    314\u001b[0m     next_target,\n\u001b[0;32m    315\u001b[0m     next_target_grad_parts,\n\u001b[0;32m    316\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py:336\u001b[0m, in \u001b[0;36m_one_step\u001b[1;34m(target_fn, step_sizes, get_velocity_parts, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mfor\u001b[39;00m state_part, eps, velocity_part \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    333\u001b[0m     state_parts, step_sizes, velocity_parts):\n\u001b[0;32m    334\u001b[0m   next_state_parts\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    335\u001b[0m       state_part \u001b[39m+\u001b[39m _multiply(eps, velocity_part, dtype\u001b[39m=\u001b[39mstate_part\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m--> 336\u001b[0m [next_target, next_target_grad_parts] \u001b[39m=\u001b[39m mcmc_util\u001b[39m.\u001b[39;49mmaybe_call_fn_and_grads(\n\u001b[0;32m    337\u001b[0m     target_fn, next_state_parts)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(g \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m next_target_grad_parts):\n\u001b[0;32m    339\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    340\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mEncountered `None` gradient.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    341\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m  state_parts: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m           next_state_parts,\n\u001b[0;32m    346\u001b[0m           next_target_grad_parts))\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\util.py:297\u001b[0m, in \u001b[0;36mmaybe_call_fn_and_grads\u001b[1;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(name \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmaybe_call_fn_and_grads\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    295\u001b[0m   fn_arg_list \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(fn_arg_list) \u001b[39mif\u001b[39;00m is_list_like(fn_arg_list)\n\u001b[0;32m    296\u001b[0m                  \u001b[39melse\u001b[39;00m [fn_arg_list])\n\u001b[1;32m--> 297\u001b[0m   result, grads \u001b[39m=\u001b[39m _value_and_gradients(fn, fn_arg_list, result, grads)\n\u001b[0;32m    298\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(dtype_util\u001b[39m.\u001b[39mis_floating(r\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    299\u001b[0m              \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m (result \u001b[39mif\u001b[39;00m is_list_like(result) \u001b[39melse\u001b[39;00m [result])):  \u001b[39m# pylint: disable=superfluous-parens\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFunction result must be a `Tensor` with `float` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    301\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m`dtype`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\util.py:282\u001b[0m, in \u001b[0;36m_value_and_gradients\u001b[1;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[0;32m    279\u001b[0m   grads \u001b[39m=\u001b[39m _convert_to_tensor(grads, \u001b[39m'\u001b[39m\u001b[39mfn_grad\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    280\u001b[0m   \u001b[39mreturn\u001b[39;00m result, grads\n\u001b[1;32m--> 282\u001b[0m _, grads \u001b[39m=\u001b[39m tfp_math_value_and_gradients(fn, fn_arg_list)\n\u001b[0;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m result, grads\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py:108\u001b[0m, in \u001b[0;36mvalue_and_gradient\u001b[1;34m(f, output_gradients, use_gradient_tape, auto_unpack_single_arg, has_aux, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Computes `f(*args, **kwargs)` and its gradients wrt to `args`, `kwargs`.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39mThe function `f` is invoked according to one of the following rules:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39m    are the gradients of `y` with respect to each of `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(name \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvalue_and_gradient\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 108\u001b[0m   \u001b[39mreturn\u001b[39;00m _value_and_grad_impl(\n\u001b[0;32m    109\u001b[0m       f,\n\u001b[0;32m    110\u001b[0m       _gradient_new \u001b[39mif\u001b[39;49;00m tf\u001b[39m.\u001b[39;49mexecuting_eagerly() \u001b[39mor\u001b[39;49;00m use_gradient_tape \u001b[39melse\u001b[39;49;00m\n\u001b[0;32m    111\u001b[0m       _gradient_old,\n\u001b[0;32m    112\u001b[0m       \u001b[39m*\u001b[39;49margs,\n\u001b[0;32m    113\u001b[0m       output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m    114\u001b[0m       auto_unpack_single_arg\u001b[39m=\u001b[39;49mauto_unpack_single_arg,\n\u001b[0;32m    115\u001b[0m       expand_tf_modules_as_trainable_vars\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    116\u001b[0m       has_aux\u001b[39m=\u001b[39;49mhas_aux,\n\u001b[0;32m    117\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py:378\u001b[0m, in \u001b[0;36m_value_and_grad_impl\u001b[1;34m(f, grad_fn, output_gradients, auto_unpack_single_arg, expand_tf_modules_as_trainable_vars, has_aux, *args, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m   real_f \u001b[39m=\u001b[39m f\n\u001b[0;32m    375\u001b[0m   f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: (real_f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    376\u001b[0m                                \u001b[39mif\u001b[39;00m _has_args(real_f) \u001b[39melse\u001b[39;00m real_f(), ())\n\u001b[1;32m--> 378\u001b[0m y, dydx, aux \u001b[39m=\u001b[39m grad_fn(\u001b[39mlambda\u001b[39;49;00m: f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mif\u001b[39;49;00m _has_args(f) \u001b[39melse\u001b[39;49;00m f(),\n\u001b[0;32m    379\u001b[0m                        tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mflatten([expand_args, expand_kwargs]),\n\u001b[0;32m    380\u001b[0m                        output_gradients)\n\u001b[0;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m do_unpack:\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py:324\u001b[0m, in \u001b[0;36m_gradient_new\u001b[1;34m(f, xs, grad_ys)\u001b[0m\n\u001b[0;32m    322\u001b[0m   \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs:\n\u001b[0;32m    323\u001b[0m     tape\u001b[39m.\u001b[39mwatch(x)\n\u001b[1;32m--> 324\u001b[0m   y, aux \u001b[39m=\u001b[39m f()\n\u001b[0;32m    325\u001b[0m \u001b[39mreturn\u001b[39;00m y, tape\u001b[39m.\u001b[39mgradient(y, xs, output_gradients\u001b[39m=\u001b[39mgrad_ys), aux\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py:378\u001b[0m, in \u001b[0;36m_value_and_grad_impl.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    374\u001b[0m   real_f \u001b[39m=\u001b[39m f\n\u001b[0;32m    375\u001b[0m   f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: (real_f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    376\u001b[0m                                \u001b[39mif\u001b[39;00m _has_args(real_f) \u001b[39melse\u001b[39;00m real_f(), ())\n\u001b[1;32m--> 378\u001b[0m y, dydx, aux \u001b[39m=\u001b[39m grad_fn(\u001b[39mlambda\u001b[39;00m: f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mif\u001b[39;00m _has_args(f) \u001b[39melse\u001b[39;00m f(),\n\u001b[0;32m    379\u001b[0m                        tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten([expand_args, expand_kwargs]),\n\u001b[0;32m    380\u001b[0m                        output_gradients)\n\u001b[0;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m do_unpack:\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py:375\u001b[0m, in \u001b[0;36m_value_and_grad_impl.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m    374\u001b[0m   real_f \u001b[39m=\u001b[39m f\n\u001b[1;32m--> 375\u001b[0m   f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: (real_f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    376\u001b[0m                                \u001b[39mif\u001b[39;00m _has_args(real_f) \u001b[39melse\u001b[39;00m real_f(), ())\n\u001b[0;32m    378\u001b[0m y, dydx, aux \u001b[39m=\u001b[39m grad_fn(\u001b[39mlambda\u001b[39;00m: f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mif\u001b[39;00m _has_args(f) \u001b[39melse\u001b[39;00m f(),\n\u001b[0;32m    379\u001b[0m                        tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten([expand_args, expand_kwargs]),\n\u001b[0;32m    380\u001b[0m                        output_gradients)\n\u001b[0;32m    381\u001b[0m dydx_args, dydx_kwargs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    382\u001b[0m     [expand_args, expand_kwargs], dydx)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\transformed_kernel.py:123\u001b[0m, in \u001b[0;36mmake_transformed_log_prob.<locals>.transformed_log_prob_fn\u001b[1;34m(*state_parts)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m enable_bijector_caching:\n\u001b[0;32m    122\u001b[0m   state_parts \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39midentity(sp) \u001b[39mfor\u001b[39;00m sp \u001b[39min\u001b[39;00m state_parts]\n\u001b[1;32m--> 123\u001b[0m tlp \u001b[39m=\u001b[39m log_prob_fn(\u001b[39m*\u001b[39;49mfn(state_parts))\n\u001b[0;32m    124\u001b[0m tlp_rank \u001b[39m=\u001b[39m prefer_static\u001b[39m.\u001b[39mrank(tlp)\n\u001b[0;32m    125\u001b[0m event_ndims \u001b[39m=\u001b[39m [(prefer_static\u001b[39m.\u001b[39mrank(sp) \u001b[39m-\u001b[39m tlp_rank) \u001b[39mfor\u001b[39;00m sp \u001b[39min\u001b[39;00m state_parts]\n",
      "Cell \u001b[1;32mIn[203], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m      5\u001b[0m initial_chain_state \u001b[39m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     tf\u001b[39m.\u001b[39mcast(\u001b[39m1.\u001b[39m,dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32) \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mones([], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minit_alpha\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32),\n\u001b[0;32m      7\u001b[0m     tf\u001b[39m.\u001b[39mcast(\u001b[39m0.01\u001b[39m,dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32) \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mones([], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minit_beta\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32),\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m     10\u001b[0m unconstraining_bijectors \u001b[39m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     tfp\u001b[39m.\u001b[39mbijectors\u001b[39m.\u001b[39mIdentity(), \u001b[39m#alpha\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     tfp\u001b[39m.\u001b[39mbijectors\u001b[39m.\u001b[39mIdentity(), \u001b[39m#beta # Figure out proper bijector for beta TODO\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ]\n\u001b[1;32m---> 15\u001b[0m unnormalized_posterior_log_prob \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs: risk_posterior_log_prob(X_data_, Y_data_, \u001b[39m*\u001b[39;49margs)\n",
      "Cell \u001b[1;32mIn[201], line 28\u001b[0m, in \u001b[0;36mrisk_posterior_log_prob\u001b[1;34m(X_data_, Y_data_, alpha, beta)\u001b[0m\n\u001b[0;32m     22\u001b[0m mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(alpha \u001b[39m+\u001b[39m beta \u001b[39m*\u001b[39m X_data_)\n\u001b[0;32m     23\u001b[0m rv_observed \u001b[39m=\u001b[39m tfd\u001b[39m.\u001b[39mNormal(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m\"\u001b[39m, loc\u001b[39m=\u001b[39mmean, scale\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m) \u001b[39m# hardcoded sigma TODO\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     rv_alpha\u001b[39m.\u001b[39mlog_prob(alpha)\n\u001b[0;32m     27\u001b[0m     \u001b[39m+\u001b[39m rv_beta\u001b[39m.\u001b[39mlog_prob(beta)\n\u001b[1;32m---> 28\u001b[0m     \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(rv_observed\u001b[39m.\u001b[39;49mlog_prob(Y_data_))\n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1287\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[1;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog_prob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1276\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \n\u001b[0;32m   1278\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[39m      values of type `self.dtype`.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_log_prob(value, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1269\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[1;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[0;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_log_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 1269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_prob(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1270\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1271\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\normal.py:187\u001b[0m, in \u001b[0;36mNormal._log_prob\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m scale \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale)\n\u001b[0;32m    185\u001b[0m log_unnormalized \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msquared_difference(\n\u001b[0;32m    186\u001b[0m     x \u001b[39m/\u001b[39m scale, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m/\u001b[39m scale)\n\u001b[1;32m--> 187\u001b[0m log_normalization \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconstant(\n\u001b[0;32m    188\u001b[0m     \u001b[39m0.5\u001b[39;49m \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mlog(\u001b[39m2.\u001b[39;49m \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mpi), dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype) \u001b[39m+\u001b[39;49m tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mlog(scale)\n\u001b[0;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m log_unnormalized \u001b[39m-\u001b[39m log_normalization\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1407\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1407\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1408\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1409\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1757\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1755\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39madd(x, y, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   1756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49madd_v2(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\au475271\\Miniconda3\\envs\\py38-bayes-surv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:490\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    489\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    491\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAddV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    493\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the step_size.\n",
    "step_size = 0.5\n",
    "\n",
    "# Defining the HMC\n",
    "kernel=tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "        num_leapfrog_steps=2,\n",
    "        step_size=step_size,\n",
    "        state_gradients_are_stopped=True),        \n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    inner_kernel=kernel, num_adaptation_steps=int(burnin * 0.8))\n",
    "\n",
    "# Sampling from the chain.\n",
    "[alpha, beta, sigma], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results = number_of_steps,\n",
    "    num_burnin_steps = burnin,\n",
    "    current_state=initial_chain_state,\n",
    "    kernel=kernel,\n",
    "    name='HMC_sampling'\n",
    ")\n",
    "\n",
    "# Initialize any created variables for preconditions\n",
    "init_g = tf.global_variables_initializer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-bayes-surv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7b1ff9a052203a82117823168d493ad388bb60e68760c9918163fd0855db357"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
