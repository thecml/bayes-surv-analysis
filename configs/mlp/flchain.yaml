# Network
network_layers: [32, 32]
activiation_fn: "selu"
dropout_rate: 0.25
l2_reg: 0
batch_size: 32
early_stop: True
patience: 5

optimizer:
  class_name: Adam
  config:
    learning_rate: 0.0005