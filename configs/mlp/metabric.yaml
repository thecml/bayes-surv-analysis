# Network
network_layers: [16]
activiation_fn: "relu"
dropout_rate: 0.25
l2_reg: 0.05
batch_size: 32

optimizer:
  class_name: SGD
  config:
    learning_rate: 0.01
    momentum: 0.97
    decay: 0.00001

loss_fn:
  class_name: CoxPHLoss
  config:
    reduction: 'auto'
    name: None