# Network
network_layers: [16, 16, 16]
activiation_fn: "selu"
dropout_rate: null
l2_reg: 0.1

optimizer:
  class_name: Adam
  config:
    learning_rate: 0.001
    momentum: 0
    decay: 0.0001

loss_fn:
  class_name: CoxPHLoss
  config:
    reduction: 'auto'
    name: None